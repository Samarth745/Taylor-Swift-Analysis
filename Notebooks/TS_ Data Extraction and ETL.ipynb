{"cells":[{"cell_type":"markdown","source":["## Look what you made us do?\n","\n","A Data-Driven Exploration of Taylor's Discography\n","\n","This project is a deep dive into Taylor Swift's music, We're gonna use the power of data to uncover the hidden secrets within her discography.\n","\n","First we start with ETL to finally create 3 data sets that we require fot our Analysis\n","### DATA 1: Feature Frenzy: The Invisible String ️‍♀️\n","\n","We're bringing in Spotify's API like a decoder ring for Taylor's music.  This lets us create data points that describe a song's sonic personality,  like:\n","\n","* `Danceability:` How likely are you to **shake it off** to this song? <br>\n","* `Valence:` Happy and carefree like **22** or a touch melancholic like **Teardrops on My Guitar**? <br>\n","\n","### DATA 2: Blank Space: (Fill it with Repeated Rhymes)\n","\n","Ever wondered which words Taylor loves to use together? Or how her rhyming style has evolved throughout her career?  <br>This is where we dissect her rhymes line by line and see if they're **never ever getting back together**.\n","\n","### DATA 3: Call It What You Want (Love Story, Breakup Song, You Decide!)\n","\n","We've compiled a list of words that scream \"love song\" and another list that embodies all things \"breakup.\"<br> Then, we'll use sentiment analysis tools to understand the overall emotional tone of the lyrics.<br> Sad words = breakup anthem, happy words = love song celebration!\n","\n","Based on this analysis, we'll classify each song into three categories:\n","\n","* Love Songs\n","* Breakup Songs\n","* The ever-intriguing \"Unknown\" Category\n","\n","\n"],"metadata":{"id":"lfA8mPcEp24H"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4358,"status":"ok","timestamp":1711344236551,"user":{"displayName":"samarth prabhu","userId":"04263059416125825333"},"user_tz":-330},"id":"cQw33G1f4mWb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1437d14-8428-40cc-c3ad-de2c552ad57b","cellView":"form"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}],"source":["#@title AllImports\n","import pandas as pd\n","import gensim\n","from gensim import corpora\n","\n","import re\n","from collections import Counter\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import nltk\n","nltk.download('punkt')\n","nltk.download(\"stopwords\")\n","nltk.download(\"wordnet\")\n","\n","nltk.download('vader_lexicon')\n","from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","\n","from gensim.models import LdaModel\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5ZBXkgGVIS8"},"outputs":[],"source":["#@title AllFiles\n","\n","import os\n","# Get the current working directory\n","current_directory = \"/content/drive/MyDrive/Colab Notebooks/TS Rant\"\n","\n","# List all files in the current directory\n","file_paths = [os.path.join(current_directory+\"/archive\", f) for f in os.listdir(current_directory+\"/archive\") if os.path.isfile(os.path.join(current_directory+\"/archive\", f))]\n","\n","#@title Create DataFrame\n","\n","## Read all data using filepaths and concatenate all data\n","maindf=pd.DataFrame()\n","for file_path in file_paths:\n","  df=pd.read_csv(file_path)\n","  df[\"File\"]=file_path.split(\"/\")[2].split(\"-\")[0]\n","  maindf = pd.concat([maindf,df])\n","  #scan_data(df)\n","#scan_data(maindf)\n","\n","#@title Function to preprocess text\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    tokens = word_tokenize(text)\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word not in stop_words]\n","    lemmatizer = WordNetLemmatizer()  # Initialize lemmatizer\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","    return tokens\n","\n","#@title Get Lyrics DataFrame\n","justlyric = maindf.groupby(\"track_title\").agg({\"lyric\":'sum'})\n","justlyric[\"preprocesslyric\"] = justlyric[\"lyric\"].apply(lambda x:preprocess_text(x))\n","justlyric.reset_index(inplace=True)"]},{"cell_type":"markdown","source":["# Data ETL"],"metadata":{"id":"T2TrxkPFzyK2"}},{"cell_type":"markdown","source":["## Topics of Songs\n"],"metadata":{"id":"1eIoduE4dOj9"}},{"cell_type":"code","source":["#@title List of Words\n","breakup_words = [\n","    \"tears\", \"heartbreak\", \"alone\", \"pain\", \"goodbye\", \"sadness\", \"miss\", \"cry\",\n","    \"empty\", \"regret\", \"broken\", \"forget\", \"lost\", \"painful\", \"memories\", \"farewell\",\n","    \"lonely\", \"sorrow\", \"heartache\", \"hurt\", \"part\", \"betray\", \"teardrops\", \"sigh\",\n","    \"grief\", \"let go\", \"missed\", \"longing\", \"end\", \"break\", \"painfully\", \"ache\",\n","    \"mistake\", \"leave\", \"depart\", \"teardrop\", \"disappointment\", \"forlorn\",\n","    \"lament\", \"anguish\", \"despair\", \"grieve\", \"suffer\", \"regretful\", \"bittersweet\",\n","    \"heartfelt\", \"desolate\", \"unrequited\", \"downhearted\", \"melancholy\", \"pining\",\n","    \"rejection\", \"unhappy\", \"woeful\", \"woe\", \"disheartened\", \"betrayal\",\n","    \"heartrend\", \"heartrending\", \"heartstrings\", \"melancholic\", \"mourn\", \"pang\",\n","    \"separation\", \"unrequited\", \"anguished\", \"crush\", \"devastate\", \"devastation\",\n","    \"heartbrokenness\", \"lamentation\", \"loneliness\", \"lost\",\n","    \"romantic rejection\", \"romantic loss\", \"sad\", \"sob\", \"sorrowful\", \"tearful\",\n","    \"wail\", \"weep\", \"weeping\", \"whimper\", \"yowl\"\n","]\n","\n","love_words = [\n","    \"cherished\", \"adored\", \"treasured\", \"devotion\", \"affection\", \"intimacy\",\n","    \"companionship\", \"soulmate\", \"passion\", \"inseparable\", \"blissful\", \"enchanted\",\n","    \"euphoric\", \"contentment\", \"harmony\", \"trust\", \"respect\", \"understanding\",\n","    \"supportive\", \"encouraging\", \"compassionate\", \"playful\", \"laughter\", \"joy\",\n","    \"excitement\", \"admiration\", \"gratitude\", \"appreciation\", \"vulnerability\",\n","    \"honesty\", \"communication\", \"growth\", \"security\", \"stability\", \"commitment\",\n","    \"loyalty\", \"partnership\", \"teamwork\", \"desire\", \"adventure\", \"future\",\n","    \"togetherness\", \"forever\", \"yearning\", \"dream\", \"hold\", \"inspire\", \"moonlight\",\n","    \"promise\", \"pure\", \"smitten\", \"spark\", \"starry\", \"sunshine\", \"truelove\",\n","    \"unconditional\", \"whisper\", \"yearn\", \"bliss\", \"destiny\", \"endless\", \"everlasting\",\n","    \"flame\", \"gaze\", \"harmony\", \"magic\", \"paradise\", \"poetry\", \"sunset\", \"wonder\", \"love\", \"lover\", 'marry'\n","\n","]\n","\n","love_words = preprocess_text(\" \".join(love_words))\n","breakup_words = preprocess_text(\" \".join(breakup_words))"],"metadata":{"id":"bspUgAYxdQ_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Classify Song Function\n","def get_sentiment_score(lyrics):\n","  analyzer = SentimentIntensityAnalyzer()\n","  sentiment = analyzer.polarity_scores(lyrics)\n","  return sentiment['compound']\n","\n","def check_domain_words(lyrics, word_list):\n","  count = 0\n","  for word in word_list:\n","    if word in lyrics:\n","      count += 1\n","  return count\n","\n","\n","def classify_song(new_lyrics):\n","  cleaned_new_lyrics = preprocess_text(new_lyrics)\n","  sentiment_score = get_sentiment_score(new_lyrics)\n","  love_word_count = check_domain_words(cleaned_new_lyrics, love_words)\n","  breakup_word_count = check_domain_words(cleaned_new_lyrics, breakup_words)\n","  print(f\"Love count {love_word_count}\")\n","  print(f\"Breakup Count count {breakup_word_count}\")\n","  # Rule-based classification with sentiment as a tie-breaker\n","  if love_word_count > breakup_word_count:# or sentiment_score > 0.5:\n","    return \"Love Song\"\n","\n","  elif breakup_word_count > love_word_count and sentiment_score < 0.1:\n","    return \"Breakup Song\"\n","  else:\n","    return \"Unknown\"\n","\n"],"metadata":{"id":"Jmb1SKzogCUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Assigning Topics\n","justlyric[\"Type\"]=justlyric[\"lyric\"].apply(lambda x:classify_song(x))"],"metadata":{"id":"19wYeivig-g0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title SavingDF\n","justlyric.to_excel(current_directory+\"/LyricsFeatures.xlsx\", index=False)"],"metadata":{"cellView":"form","id":"nEoxChC7n_Ig"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Counting Repeated Rhymes/Combination of words\n","What are the kind of repetation that happens when different songs are considered"],"metadata":{"id":"gNwf0Df4xOFD"}},{"cell_type":"code","source":["#@title Function to build word matrix\n","def build_word_matrix(paragraph):\n","  word_matrix = {}\n","  words = preprocess_text(paragraph)\n","  for i in range(len(words) - 1):\n","    for j in range(len(words) - 1):\n","    if i==j:\n","      pass\n","    else:\n","      word_pair = (words[i], words[j])\n","      if word_pair not in word_matrix:\n","        word_matrix[word_pair] = 1\n","      else:\n","        word_matrix[word_pair] += 1\n","  return word_matrix"],"metadata":{"cellView":"form","id":"us3yugEPjt20"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRg8Rjx8keTW","cellView":"form"},"outputs":[],"source":["#@title Iterate and create the final word matrix\n","word_matrix = {}\n","new_df=pd.DataFrame()\n","lines_consider = 10\n","for iloc in range(0,maindf.shape[0]-maindf.shape[0]%lines_consider,lines_consider):\n","  main_sentence=\"\"\n","  for sentence in list(maindf.iloc[iloc:iloc+lines_consider][\"lyric\"].apply(lambda x:x+\" \")):\n","    main_sentence = main_sentence+sentence\n","    matrix = build_word_matrix(main_sentence)\n","\n","    df = pd.DataFrame.from_dict(matrix, orient='index', columns=['Count'])\n","    df.index = pd.MultiIndex.from_tuples(df.index, names=['Word1', 'Word2'])\n","    new_df = pd.concat([new_df, df])\n","\n","new_df.reset_index(inplace=True)\n","new_df_1 = new_df[new_df[\"Word1\"]!=new_df[\"Word2\"]]\n","new_df_1.sort_values(by='Count',ascending=False, inplace=True)\n","new_df_1_counter = pd.DataFrame(new_df_1.groupby([\"Word1\", \"Word2\"], as_index=False)[\"Count\"].sum()).sort_values(by=\"Count\", ascending=False)\n","new_df_1_counter.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","source":["#@title get Tracks which use combination of words using lookup\n","def get_tracks(row):\n","  a = row[\"Word1\"]\n","  b = row[\"Word2\"]\n","  listofsongs = justlyric[justlyric['preprocesslyric'].apply(lambda x:(a in x)&(b in x))][\"track_title\"].to_list()\n","  return listofsongs\n","\n","new_df_1_counter[\"List Of Songs\"]=new_df_1_counter.apply(lambda x:get_tracks(x),axis=1)\n","new_df_1_counter[\"total songs\"] = new_df_1_counter[\"List Of Songs\"].apply(lambda x:len(x))\n","new_df_1_counter.to_excel(\"/content/drive/MyDrive/Colab Notebooks/TS Rant/WordCounts.xlsx\")"],"metadata":{"cellView":"form","id":"qkaT30W4kLGc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Get Tracks Rhyme Score\n","def rhyme_score(row):\n","  score=0\n","  word1 = row[\"Word1\"]\n","  word2 = row[\"Word2\"]\n","  for i in range(1, min(len(word1), len(word2)) + 1):\n","      if word1[-i] == word2[-i]:\n","          score += 1\n","      else:\n","          break\n","  return score\n","\n","new_df_1_counter[\"RhymeScore\"]=new_df_1_counter.apply(lambda x:rhyme_score(x),axis=1)"],"metadata":{"id":"5xht3fR1JNVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title SaveDF\n","new_df_1_counter[new_df_1_counter['RhymeScore']>1].sort_values(by=['total songs',\"RhymeScore\"], ascending=False).to_excel(\"/content/drive/MyDrive/Colab Notebooks/TS Rant/WordCounts.xlsx\", index=False)"],"metadata":{"id":"KEo7bHpX-Jz8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Song Features\n"],"metadata":{"id":"7DdR9sOcSv3i"}},{"cell_type":"code","source":["#@title Import Spotify API Libraries\n","!pip install spotipy\n","import spotipy\n","from spotipy.oauth2 import SpotifyClientCredentials\n","import pandas as pd\n","import numpy as np\n","from google.colab import userdata\n","clientpass = userdata.get('cleint_password')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AbLfDXdS2My","executionInfo":{"status":"ok","timestamp":1710937423139,"user_tz":-330,"elapsed":9583,"user":{"displayName":"samarth prabhu","userId":"04263059416125825333"}},"outputId":"ddaa1930-d7ba-464a-9809-724b4a489a45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spotipy in /usr/local/lib/python3.10/dist-packages (2.23.0)\n","Requirement already satisfied: redis>=3.5.3 in /usr/local/lib/python3.10/dist-packages (from spotipy) (5.0.3)\n","Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (2.31.0)\n","Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (1.16.0)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (2.0.7)\n","Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis>=3.5.3->spotipy) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (2024.2.2)\n"]}]},{"cell_type":"code","source":["#@title Authentication - without user\n","client_credentials_manager = SpotifyClientCredentials(client_id='f76ee452a0464e9198b742acce8b3ff6', client_secret=clientpass)\n","sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)"],"metadata":{"cellView":"form","id":"fji7nYBxS0_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title GetTrackDetails - Function\n","def get_track_details(track_name):\n","  try:\n","    input_song = sp.search(f'track:{track_name}%',limit=1)['tracks']['items'][0]['id']\n","    input_song_features = sp.audio_features(input_song)\n","    track_details = pd.DataFrame(input_song_features)\n","    track_details[\"track_title\"]=track_name\n","    track_details = track_details[['track_title','danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n","       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n","       'type', 'id', 'uri', 'track_href', 'analysis_url', 'duration_ms',\n","       'time_signature']]\n","\n","  except:\n","    track_details = pd.DataFrame(columns=['track_title','danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n","       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n","       'type', 'id', 'uri', 'track_href', 'analysis_url', 'duration_ms',\n","       'time_signature'])\n","    track_details['track_title']=track_name\n","  return track_details"],"metadata":{"id":"hTzbSC6ZTcOg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Create SongFeaturesDF\n","song_features = pd.DataFrame()\n","for song in maindf[\"track_title\"].unique():\n","  song_df = get_track_details(song)\n","  song_features = pd.concat([song_features, song_df])\n","\n","song_features[\"popularity\"]=song_features[\"id\"].apply(lambda x: sp.track(x)[\"popularity\"])"],"metadata":{"id":"N1RlzbuWTwVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Any Null Values\n","song_features.isnull().sum().values!=0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtQL6SjRWifD","executionInfo":{"status":"ok","timestamp":1710929953280,"user_tz":-330,"elapsed":401,"user":{"displayName":"samarth prabhu","userId":"04263059416125825333"}},"outputId":"cbd9b8e2-ea83-4e32-f7ef-c7eb03780328"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([False, False, False, False, False, False, False, False, False,\n","       False, False, False, False, False, False, False, False, False,\n","       False])"]},"metadata":{},"execution_count":273}]},{"cell_type":"code","source":["#@title SaveDF\n","song_features.to_excel(\"/content/drive/MyDrive/Colab Notebooks/TS Rant/SongFeatures.xlsx\", index=False)"],"metadata":{"cellView":"form","id":"E4nHVvvxyTXp"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1SoguQRaVH3onxrq9kBA3PCSRduhAKaPx","authorship_tag":"ABX9TyMV6p/KPezpN/O8A7SxAFCO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}